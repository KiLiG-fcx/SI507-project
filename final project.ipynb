{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64714296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import os,re,us\n",
    "import json\n",
    "import plotly.express as px\n",
    "px.set_mapbox_access_token(\"pk.eyJ1IjoiZmN4LWtpbGlnIiwiYSI6ImNsMHIwaG5rODJmY2QzYnM1NW1rcHRjOHMifQ.1kdhIW8dwvtyNDFHOCyx5g\")\n",
    "API_Key = 'pzFDw36S40GxhJLXmtLYN4MfW'\n",
    "API_Key_Secret = 'bV7FUFPK4Eaqmts26r26POmC7JNlgyt7vSdR63QDEHSms8UL5J'\n",
    "Bearer_Token = 'AAAAAAAAAAAAAAAAAAAAAKGFbQEAAAAAWcrusWRsy0QE3lLWsvF7lPbnJfc%3DyWDpEWxNK1yLhFsRjSe7c9v5HoGXqIcX88Qmr4QGRI38lfgn15'\n",
    "Access_Token = '1506028898525450241-LqmCE8DmRY7KSMOJL0WXULWyr7iA8D'\n",
    "Access_Token_Secret = 'IXeFTTYLsXhc6lCt5POk7dgtH4No42dvtA4ZeHPxSp7DO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff1fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addpollutant(json):\n",
    "    if (json['parameter_code']==\"42401\"):\n",
    "        return (\"SO2\", abs(json['arithmetic_mean']))\n",
    "    elif (json['parameter_code']==\"42101\"):\n",
    "        return (\"CO\",abs(json['arithmetic_mean']))\n",
    "    elif (json['parameter_code']==\"42602\"):\n",
    "        return ('NO2',abs(json['arithmetic_mean']))\n",
    "    elif (json['parameter_code']==\"44201\"):\n",
    "        return ('Ozone',abs(json['arithmetic_mean']))\n",
    "    elif (json['parameter_code']==\"81102\"):\n",
    "        return ('PM10',abs(json['arithmetic_mean']))\n",
    "    elif (json['parameter_code']==\"88101\"):\n",
    "        return ('PM25',abs(json['arithmetic_mean']))\n",
    "\n",
    "class Site:\n",
    "    def __init__(self,json=None):\n",
    "        self.statecode=json['state_code']\n",
    "        self.latitude=json['latitude']\n",
    "        self.longitude=json['longitude']\n",
    "        self.airname, self.concentration=addpollutant(json)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac3d1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {Bearer_Token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    #print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3110456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pop(json):\n",
    "    result=0\n",
    "    for v in json['public_metrics'].values():\n",
    "        result += v\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8588e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(self,json):\n",
    "        self.id=json['id']\n",
    "        self.text=json['text']\n",
    "        self.popularity=get_pop(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93269ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getalltweets(fips,num):\n",
    "    StateName=us.states.lookup(str(fips).zfill(2)).name\n",
    "    query=f\"{StateName} pollution\"\n",
    "    query_params={\n",
    "        'query':query,\n",
    "        'max_results':num,\n",
    "        'tweet.fields':'public_metrics',\n",
    "    }\n",
    "    result=[]\n",
    "    c=connect_to_endpoint(search_url,query_params)\n",
    "    #print(c['data'])\n",
    "    try:\n",
    "        for items in c['data']:\n",
    "            result.append(Tweet(items))\n",
    "        return c['data'],result\n",
    "    except:\n",
    "        result.append('No data recently!')\n",
    "        return {},result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "522bcedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateNews:\n",
    "    def __init__(self,fips,num):\n",
    "        self.state=us.states.lookup(str(fips).zfill(2)).name\n",
    "        self.json, self.tweet=getalltweets(fips,num)\n",
    "        self.number=num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46bdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitefile='air_cache.json'  # cache for air pollution data archived site\n",
    "tweetfile='tweet_cache.json'  # cache for daily tweets capture\n",
    "def open_cache(filename):\n",
    "    try:\n",
    "        cache_file = open(filename, 'r')\n",
    "        cache_contents = cache_file.read()\n",
    "        cache_dict = json.loads(cache_contents)\n",
    "        cache_file.close()\n",
    "    except:\n",
    "        cache_dict = {}\n",
    "    return cache_dict\n",
    "\n",
    "def save_cache(filename,cache_dict):\n",
    "    dumped_json_cache = json.dumps(cache_dict)\n",
    "    fw = open(filename,\"w\")\n",
    "    fw.write(dumped_json_cache)\n",
    "    fw.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "911ac936",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url=\"https://aqs.epa.gov/data/api/dailyData/byState?email=mingyuli@umich.edu&key=greenkit68&param=\"\n",
    "pollutant_para={'co':\"42101\",'so2':\"42401\",'no2':\"42602\",'ozone':\"44201\",'pm10':\"81102\",'pm25':\"88101\"}\n",
    "\n",
    "def geturl(pollutant_name,fips,date):\n",
    "    url=base_url+pollutant_para[pollutant_name]+\"&bdate=\"+date+\"&edate=\"+date+\"&state=\"+str(fips).zfill(2)\n",
    "    return url\n",
    "\n",
    "def getjson(url):\n",
    "    return requests.get(url).json()['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ad3f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pollutant_cache(date, fips, pollutant):\n",
    "    have_captured = pollutant + str(fips).zfill(2) + str(date)\n",
    "    dic = open_cache(sitefile)\n",
    "    if (have_captured in dic.keys()): # have found data in cache json file\n",
    "        #print(\"find!\")\n",
    "        return dic[have_captured]\n",
    "    else:\n",
    "        #print(\"create cache\")\n",
    "        url=geturl(pollutant,str(fips),str(date)) # get the url for that date\n",
    "        jsondata=getjson(url)\n",
    "        dic[have_captured]=jsondata\n",
    "        save_cache(sitefile,dic)\n",
    "        return jsondata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d7f9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "def save_tweet_cache(fips, num):\n",
    "    tweet_dict = open_cache(tweetfile)\n",
    "    have_captured = str(fips)+str(now.day)+str(now.hour)\n",
    "    if have_captured in tweet_dict.keys():\n",
    "        return tweet_dict[have_captured]\n",
    "    else:\n",
    "        news=StateNews(fips, num)\n",
    "        #print(news.tweet[1].text)\n",
    "        tweet_dict[have_captured]=news.json\n",
    "        save_cache(tweetfile,tweet_dict)\n",
    "        return news.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9368f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', \n",
    "             'Colorado', 'Connecticut', 'Washington DC', 'Delaware', 'Florida',\n",
    "             'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana',\n",
    "             'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', \n",
    "             'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', \n",
    "             'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', \n",
    "             'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', \n",
    "             'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', \n",
    "             'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', \n",
    "             'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a521f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def airToDf(date,pollutant,fips):\n",
    "    # transfer json to dataframe and plot\n",
    "    jsonlst = save_pollutant_cache(date,fips,pollutant)\n",
    "    sitenum = len(jsonlst)\n",
    "    d = np.zeros((sitenum,3))\n",
    "    sitelst = []\n",
    "    for json in jsonlst:\n",
    "        sitelst.append(Site(json))\n",
    "    for i in range(sitenum):\n",
    "        d[i,0] = sitelst[i].latitude\n",
    "        d[i,1] = sitelst[i].longitude\n",
    "        d[i,2] = sitelst[i].concentration\n",
    "    return pd.DataFrame(d, columns=['latitude','longitude','concentration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e800388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import Dash, html, dcc, Input, Output, State\n",
    "import dash_bootstrap_components as dbc\n",
    "app = JupyterDash(external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b83b0098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "SELECT_STYLE = {\n",
    "    \"top\": 0,\n",
    "    \"left\": 0,\n",
    "    \"bottom\": 0,\n",
    "    \"width\": \"18rem\",\n",
    "    \"height\": \"100%\",\n",
    "    \"padding\": \"1rem 1rem\",\n",
    "    \"backgroundColor\": \"#ebebeb\",\n",
    "    'display': 'inline-block',\n",
    "    \"border\":\"1px #b5b5b5 solid\",\n",
    "}\n",
    "\n",
    "TWEET_STYLE = {\n",
    "    \"maxHeight\": \"600px\", \n",
    "    \"overflow\": \"scroll\"\n",
    "}\n",
    "\n",
    "TWEETBAR_STYLE = {\n",
    "    \"left\": 0,\n",
    "    \"padding-top\": \"1rem\",\n",
    "    \"padding-left\": \"1rem\",\n",
    "    \"padding-right\": \"1rem\",\n",
    "    \"height\": \"100%\",\n",
    "    \"backgroundColor\": \"#ebebeb\",\n",
    "    'display': 'inline-block',\n",
    "    \"border\":\"1px #b5b5b5 solid\",\n",
    "}\n",
    "\n",
    "selectbar = html.Div(\n",
    "    [\n",
    "        html.H3('Pollutant Name'),\n",
    "        dcc.RadioItems(id = 'pollutant-radio',\n",
    "                        options = [{'label':'PM2.5','value':'pm25'},\n",
    "                                   {'label':'PM10','value':'pm10'},\n",
    "                                   {'label':'CO', 'value':'co'},\n",
    "                                   {'label':'SO2', 'value':'so2'},\n",
    "                                   {'label':'NO2','value':'no2'},\n",
    "                                   {'label':'Ozone', 'value':'ozone'}],\n",
    "                        value = 'pm25',\n",
    "                      labelStyle={'display': 'block'}),\n",
    "        html.H3(['Select state:']),\n",
    "        dcc.Dropdown(id='state-dropdown', \n",
    "                    options=us_states, \n",
    "                    value=\"Michigan\"),\n",
    "        html.H3(['Select date:']),\n",
    "        dcc.DatePickerSingle(\n",
    "            id='datepick',\n",
    "            min_date_allowed=date(2015, 1, 1),\n",
    "            max_date_allowed=date(2021, 12, 31),\n",
    "            initial_visible_month=date(2020, 1, 1),\n",
    "            date=date(2020, 1, 1)\n",
    "        ),\n",
    "    ],\n",
    "    style = SELECT_STYLE\n",
    ")\n",
    "\n",
    "\n",
    "tweets = html.Div([\n",
    "        html.H4(['Tweet number with highest popularity:']),\n",
    "        dcc.Dropdown(id='tweet-dropdown', \n",
    "                    options=[10,15,20], \n",
    "                    value=10),\n",
    "        dbc.ListGroup(id='tweet-list',style=TWEET_STYLE)\n",
    "    ],\n",
    "    style = TWEETBAR_STYLE\n",
    ")\n",
    "\n",
    "pollutionmap = html.Div(dcc.Graph(id = 'PollutionMap'))\n",
    "\n",
    "page = html.Div(\n",
    "    [\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(selectbar),\n",
    "                dbc.Col(pollutionmap),\n",
    "                dbc.Col(tweets),\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "app.layout = page\n",
    "@app.callback(\n",
    "    Output('PollutionMap', 'figure'),\n",
    "    Input('state-dropdown','value'),\n",
    "    Input('pollutant-radio', 'value'),\n",
    "    Input('datepick', 'date'))\n",
    "\n",
    "def update_figure(state, pollutant, startdate):\n",
    "    date_object = date.fromisoformat(startdate)\n",
    "    datestring = str(startdate).replace('-','')\n",
    "    fips = int(us.states.lookup(state).fips)\n",
    "    airdf = airToDf(datestring,pollutant,fips)\n",
    "    fig = px.scatter_mapbox(airdf, lat=\"latitude\", lon=\"longitude\", size='concentration', color = 'concentration',\n",
    "                        center={'lat':statistics.median(airdf['latitude']),'lon':statistics.median(airdf['longitude'])},\n",
    "                      color_continuous_scale=px.colors.cyclical.IceFire, zoom=8,width=850, height=750)\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=5, r=5, t=5, b=5)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    Output('tweet-list','children'),\n",
    "    Input('tweet-dropdown','value'),\n",
    "    Input('state-dropdown','value')\n",
    ")\n",
    "\n",
    "def update_tweetlist(num, state):\n",
    "    fips = int(us.states.lookup(state).fips)\n",
    "    tweet_json = save_tweet_cache(fips,num)\n",
    "    all_tweets = StateNews(fips, num).tweet\n",
    "    save_tweet_cache(fips, num)\n",
    "    result = []\n",
    "    for tweet in all_tweets:\n",
    "        newitem = dbc.ListGroupItem([\n",
    "            html.Div([\n",
    "            html.P(tweet.text),\n",
    "            html.P('\\U0001F525'+'Popularity: '+str(tweet.popularity))])\n",
    "        ])\n",
    "        result.append(newitem)\n",
    "    return result\n",
    "## Deploy app -------------------------------------------------------------\n",
    "del app.config._read_only[\"requests_pathname_prefix\"]\n",
    "app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
