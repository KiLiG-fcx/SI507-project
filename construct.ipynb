{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe3a715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import us\n",
    "import json\n",
    "import plotly.express as px\n",
    "px.set_mapbox_access_token(\"pk.eyJ1IjoiZmN4LWtpbGlnIiwiYSI6ImNsMHIwaG5rODJmY2QzYnM1NW1rcHRjOHMifQ.1kdhIW8dwvtyNDFHOCyx5g\")\n",
    "API_Key = 'pzFDw36S40GxhJLXmtLYN4MfW'\n",
    "API_Key_Secret = 'bV7FUFPK4Eaqmts26r26POmC7JNlgyt7vSdR63QDEHSms8UL5J'\n",
    "Bearer_Token = 'AAAAAAAAAAAAAAAAAAAAAKGFbQEAAAAAWcrusWRsy0QE3lLWsvF7lPbnJfc%3DyWDpEWxNK1yLhFsRjSe7c9v5HoGXqIcX88Qmr4QGRI38lfgn15'\n",
    "Access_Token = '1506028898525450241-LqmCE8DmRY7KSMOJL0WXULWyr7iA8D'\n",
    "Access_Token_Secret = 'IXeFTTYLsXhc6lCt5POk7dgtH4No42dvtA4ZeHPxSp7DO'\n",
    "base_url=\"https://aqs.epa.gov/data/api/dailyData/byState?email=\"\n",
    "email = \"mingyuli@umich.edu\"\n",
    "aqi_key = \"greenkit68\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f89a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pop(json):\n",
    "    result=0\n",
    "    for v in json['public_metrics'].values():\n",
    "        result += v\n",
    "    return result\n",
    "\n",
    "class Tweet:\n",
    "    def __init__(self,json):\n",
    "        self.id=json['id']\n",
    "        self.text=json['text']\n",
    "        self.popularity=get_pop(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d0f1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateNews:\n",
    "    def __init__(self,keys,json):\n",
    "        self.state=us.states.lookup(keys[0:2]).name\n",
    "        self.tweet=getalltweets(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fa8d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getalltweets(jsonlst):\n",
    "    result = []\n",
    "    for items in jsonlst:\n",
    "        result.append(Tweet(items))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9165b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addpollutant(json):\n",
    "    if (json['parameter_code']==\"42401\"):\n",
    "        return (\"SO2\", abs(json['arithmetic_mean']))\n",
    "    elif (json['parameter_code']==\"42101\"):\n",
    "        return (\"CO\",abs(json['arithmetic_mean']))\n",
    "    elif (json['parameter_code']==\"42602\"):\n",
    "        return ('NO2',abs(json['arithmetic_mean']))\n",
    "    elif (json['parameter_code']==\"44201\"):\n",
    "        return ('Ozone',abs(json['arithmetic_mean']))\n",
    "    elif (json['parameter_code']==\"81102\"):\n",
    "        return ('PM10',abs(json['arithmetic_mean']))\n",
    "    elif (json['parameter_code']==\"88101\"):\n",
    "        return ('PM25',abs(json['arithmetic_mean']))\n",
    "\n",
    "class Site:\n",
    "    def __init__(self,json=None):\n",
    "        self.statecode=json['state_code']\n",
    "        self.latitude=json['latitude']\n",
    "        self.longitude=json['longitude']\n",
    "        self.airname, self.concentration=addpollutant(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ab59416",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitefile='air_cache.json'  # cache for air pollution data archived site\n",
    "tweetfile='tweet_cache.json'  # cache for daily tweets capture\n",
    "def open_cache(filename):\n",
    "    try:\n",
    "        cache_file = open(filename, 'r')\n",
    "        cache_contents = cache_file.read()\n",
    "        cache_dict = json.loads(cache_contents)\n",
    "        cache_file.close()\n",
    "    except:\n",
    "        cache_dict = {}\n",
    "    return cache_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9808030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allSites = []\n",
    "def save_pollutant():\n",
    "    dic = open_cache(sitefile)\n",
    "    for have_captured in dic.keys():\n",
    "        jsonlst = dic[have_captured]\n",
    "        for json in jsonlst:\n",
    "            allSites.append(Site(json))\n",
    "save_pollutant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "739e8950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0620220425\n",
      "2220220425\n",
      "3620220425\n",
      "0120220425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'California'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "allTweets = []\n",
    "def save_tweet():\n",
    "    tweet_dict = open_cache(tweetfile)\n",
    "    for k in tweet_dict.keys():\n",
    "        allTweets.append(StateNews(k,tweet_dict[k]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
